{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Part 1 -- Process Pseudobulks + Bulks\n",
    "\n",
    "In this notebook is Part 1 of a BuDDI analysis. This assumes that you have already QC-ed and preprocessed the data in a format needed for all downstream analyses.\n",
    "\n",
    "This analysis is the same as the \"liver\" analysis in the manuscript. In this example we have reference stimulated (female single-cell) data, in this analysis the stimulation is Male:Female maps to CTRL:STIM. Since we want to see how well we predict sex-specific genes in the liver, Male:Female also maps to Train:Test. To run BuDDI when you have no real \"STIM\" single-cell data, you would run it exactly the same way, but in the code below, you would not loop over the Test/Stim/Female data.\n",
    "\n",
    "Data format requirements for single-cell data:\n",
    "- processed data is not scaled\n",
    "- cells are filtered such that low-quality cells are removed (for example: filter out cells with less than 200 genes and genes expressed in less than 3 cells, and > 5% MT reads)\n",
    "- data is saved as an AnnData object and you have sample IDs, gene IDs, and cell-type labels\n",
    "- In the end we will process the data such that we have the following features in the AnnData object that we will use to generate pseudobulks:\n",
    "  - the observations have columns named: \"sample_id\", \"stim\", \"isTraining\"\n",
    "  - sample_id: unique IDs for the samples\n",
    "  - stim: is \"STIM\" or \"CTRL\", denotes if the sample is \"female\" or \"male\"\n",
    "  - isTraining: 'Train' or 'Test',  denotes if you can use the sample during training or not. In real use cases, all data will be \"Train\". To show validation of our experiment, we have access to \"Test\" data as well.\n",
    "  \n",
    "\n",
    "\n",
    "Pseudobulk features:\n",
    "- we typically generate 1000 pseudobulks per sample with random proportions, for this demo we want it to run faster so we only sample 100\n",
    "- we generate 100 pseudobulks per sample, per cell type, where the cell-type of interest is >90% of the cell-type, for this demo we want it to run faster so we only sample 10\n",
    "- we typically sample 5000 cells for each pseudobulk, for this demo we want it to run faster so we only sample 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-26 16:11:14.250303: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-26 16:11:15.171799: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-26 16:11:20.536422: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/beevol/home/davidson/miniconda3/envs/buddi_analysis/lib/python3.9/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/beevol/home/davidson/miniconda3/envs/buddi_analysis/lib/python3.9/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/beevol/home/davidson/miniconda3/envs/buddi_analysis/lib/python3.9/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/beevol/home/davidson/miniconda3/envs/buddi_analysis/lib/python3.9/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../../')\n",
    "from buddi import buddi\n",
    "from buddi.preprocessing import sc_preprocess\n",
    "\n",
    "\n",
    "# general imports\n",
    "import warnings\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from scipy.sparse import coo_matrix\n",
    "import collections\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "\n",
    "\n",
    "# Images, plots, display, and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "import sklearn as sk\n",
    "\n",
    "# matplotlib settings for Jupyter notebooks only\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import gzip\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "aug_data_path = f\"{os.getcwd()}/demo_data/augmented_liver_data/\"\n",
    "cibersort_path = f\"{os.getcwd()}/demo_data/cibersort_liver/\"\n",
    "data_path = f\"{os.getcwd()}/demo_data/processed_sc_liver/\"\n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "### set the study ###\n",
    "#####################\n",
    "\n",
    "res_name = \"all-liver\"\n",
    "in_name = \"liver_droplet_processed\"\n",
    "processed_sc_file = f\"{data_path}/{in_name}.h5ad\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "\n",
    "adata = sc.read_h5ad(processed_sc_file)\n",
    "\n",
    "adata.var_names_make_unique()  # this is unnecessary if using `var_names='gene_ids'` in `sc.read_10x_mtx`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-05d5c784bc62>:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  adata.obs[\"isTraining\"][stim_idx] = \"Test\"\n"
     ]
    }
   ],
   "source": [
    "# format metadata\n",
    "\n",
    "\n",
    "def get_stim_id(in_str):\n",
    "    out_str = \"STIM\"\n",
    "    if in_str == \"male\":\n",
    "        out_str = \"CTRL\"\n",
    "           \n",
    "    return(out_str)\n",
    "\n",
    "# get the columns we need to iterate over for making pseudobulks\n",
    "adata.obs['scpred_CellType'] = adata.obs['names_merged'].tolist()\n",
    "adata.obs['sample_id'] = adata.obs['mouse.id'].tolist()\n",
    "adata.obs['stim'] = [get_stim_id(str(x)) for x in adata.obs['sex'].tolist()]\n",
    "\n",
    "# make the gene_ids col\n",
    "adata.var['gene_ids'] = adata.var.index.tolist()\n",
    "\n",
    "# generate cell-type specific split\n",
    "adata.obs[\"isTraining\"] = \"Train\"\n",
    "stim_idx = np.where(adata.obs.stim == \"STIM\")[0]\n",
    "adata.obs[\"isTraining\"][stim_idx] = \"Test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look at some data stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>stim</th>\n",
       "      <th>CTRL</th>\n",
       "      <th>STIM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18-F-51</th>\n",
       "      <td>NaN</td>\n",
       "      <td>698.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30-M-5</th>\n",
       "      <td>362.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "stim        CTRL   STIM\n",
       "sample_id              \n",
       "18-F-51      NaN  698.0\n",
       "30-M-5     362.0    NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each sample should only have cells in with \"STIM\" or \"CTRL\"\n",
    "tab = adata.obs.groupby(['sample_id', 'stim']).size()\n",
    "tab.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hepatocyte                     296\n",
       "kupffer                        265\n",
       "NK                             197\n",
       "hepatic_sinusoid               107\n",
       "b_cell                          97\n",
       "myeloid_leukocyte               74\n",
       "plasmacytoid_dendritic_cell     17\n",
       "hepatic_stellate                 7\n",
       "Name: scpred_CellType, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how many cells per cell type\n",
    "adata.obs[\"scpred_CellType\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### write out data to use in CIBERSORTx\n",
    "we use the signature genes from CIBERSORTx as one of our inputs to BuDDI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out data for cibersort\n",
    "dense_matrix = adata.X.todense()\n",
    "\n",
    "sc_profile_file = os.path.join(aug_data_path, f\"{res_name}_sig.pkl\")\n",
    "sc_profile_path = Path(sc_profile_file)\n",
    "\n",
    "dense_df = pd.DataFrame(dense_matrix, columns = adata.var['gene_ids'])\n",
    "dense_df.insert(loc=0, column='scpred_CellType', value=adata.obs[\"scpred_CellType\"].to_list())\n",
    "\n",
    "\n",
    "pickle.dump( dense_df, open( sc_profile_path, \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make pseudobulks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running 18-F-51 STIM Train\n",
      "running 18-F-51 STIM Test\n",
      "make_prop_and_sum\n",
      "0\n",
      "100\n",
      "get_single_celltype_prop_matrix\n",
      "use_prop_make_sum\n",
      "0\n",
      "concat\n",
      "write\n",
      "running 18-F-51 CTRL Train\n",
      "running 18-F-51 CTRL Test\n",
      "running 30-M-5 STIM Train\n",
      "running 30-M-5 STIM Test\n",
      "running 30-M-5 CTRL Train\n",
      "make_prop_and_sum\n",
      "0\n",
      "100\n",
      "get_single_celltype_prop_matrix\n",
      "use_prop_make_sum\n",
      "0\n",
      "concat\n",
      "write\n",
      "running 30-M-5 CTRL Test\n"
     ]
    }
   ],
   "source": [
    "# write out the gene ids\n",
    "gene_pass = adata.var['gene_ids']\n",
    "gene_out_file = os.path.join(aug_data_path, f\"{res_name}_genes.pkl\")\n",
    "gene_out_path = Path(gene_out_file)\n",
    "pickle.dump( gene_pass, open( gene_out_path, \"wb\" ) )\n",
    "\n",
    "# metadata\n",
    "sample_order = ['18-F-51', '30-M-5']\n",
    "stim_order = ['STIM', 'CTRL']\n",
    "train_order = ['Train', 'Test']\n",
    "\n",
    "# now generate all the proportions\n",
    "total_meta_df = pd.DataFrame(columns = [\"sample_id\", \"stim\", \"isTraining\"])\n",
    "\n",
    "# no cell noise \n",
    "len_vector = adata.obs[\"scpred_CellType\"].unique().shape[0]\n",
    "cell_noise = [np.random.lognormal(0, 0, adata.var['gene_ids'].shape[0]) for i in range(len_vector)]\n",
    "\n",
    "# cell type order\n",
    "cell_order = adata.obs.scpred_CellType.unique()\n",
    "\n",
    "# simulate different number of cells\n",
    "num_cells = 100\n",
    "idx = 0\n",
    "for curr_samp in sample_order:\n",
    "  for curr_stim in stim_order:\n",
    "      for curr_train in train_order:\n",
    "\n",
    "        print(f\"running {curr_samp} {curr_stim} {curr_train}\")\n",
    "\n",
    "\n",
    "        # make the pseudobulks\n",
    "        subset_idx = np.logical_and(adata.obs.sample_id == curr_samp, adata.obs.stim == curr_stim)\n",
    "        subset_idx = np.where(np.logical_and(subset_idx, adata.obs.isTraining == curr_train))[0]\n",
    "        if len(subset_idx) == 0:\n",
    "            continue\n",
    "        \n",
    "        temp_adata = adata[subset_idx]\n",
    "\n",
    "        print(\"make_prop_and_sum\")\n",
    "        prop_df, pseudobulks_df, test_prop_df, test_pseudobulks_df = sc_preprocess.make_prop_and_sum(temp_adata, \n",
    "                                                                                num_samples=1000, \n",
    "                                                                                num_cells=num_cells,\n",
    "                                                                                use_true_prop=False,\n",
    "                                                                                cell_noise=cell_noise,\n",
    "                                                                                useSampleNoise=False)\n",
    "        # number of random pseudobulks\n",
    "        num_rand_pseudo = pseudobulks_df.shape[0] \n",
    "\n",
    "        # get the single cell type proportions\n",
    "        print(\"get_single_celltype_prop_matrix\")\n",
    "        ct_prop_df = sc_preprocess.get_single_celltype_prop_matrix(num_samp=100,\n",
    "                                                                    cell_order=cell_order)\n",
    "\n",
    "        # now get the cell-type specific pseudobulks\n",
    "        print(\"use_prop_make_sum\")\n",
    "        prop_df_sc, pseudobulks_df_sc, _ = sc_preprocess.use_prop_make_sum(temp_adata,  \n",
    "                                                                            num_cells=num_cells, \n",
    "                                                                            props_vec=ct_prop_df, \n",
    "                                                                            cell_noise=cell_noise,\n",
    "                                                                            sample_noise=None,\n",
    "                                                                            useSampleNoise=False)\n",
    "        # number of random pseudobulks\n",
    "        num_ct_pseudo = pseudobulks_df_sc.shape[0] \n",
    "\n",
    "\n",
    "        # put them together\n",
    "        print(\"concat\")        \n",
    "        prop_df = pd.concat([prop_df,prop_df_sc])\n",
    "        pseudobulks_df = pd.concat([pseudobulks_df, pseudobulks_df_sc])\n",
    "\n",
    "        # make the metadata\n",
    "        num_samps = pseudobulks_df.shape[0] \n",
    "        samp_type = [\"bulk\"]*num_samps\n",
    "        cell_prop_type = [\"random\"]*num_rand_pseudo+[\"cell_type_specific\"]*num_ct_pseudo \n",
    "        samp_type = [\"sc_ref\"]*(num_rand_pseudo+num_ct_pseudo)\n",
    "        \n",
    "        metadata_df = pd.DataFrame(data = {\"sample_id\":[curr_samp]*num_samps, \n",
    "                                          \"stim\":[curr_stim]*num_samps,\n",
    "                                          \"isTraining\":[curr_train]*num_samps,\n",
    "                                          \"cell_prop_type\":cell_prop_type,\n",
    "                                          \"samp_type\":samp_type,})\n",
    "\n",
    "        # make the proportions instead of cell counts\n",
    "        prop_df = prop_df.div(prop_df.sum(axis=1), axis=0)\n",
    "        pseudobulk_file = os.path.join(aug_data_path, f\"{res_name}_{curr_samp}_{curr_stim}_{curr_train}_pseudo_splits.pkl\")\n",
    "        prop_file = os.path.join(aug_data_path, f\"{res_name}_{curr_samp}_{curr_stim}_{curr_train}_prop_splits.pkl\")\n",
    "        meta_file = os.path.join(aug_data_path, f\"{res_name}_{curr_samp}_{curr_stim}_{curr_train}_meta_splits.pkl\")\n",
    "\n",
    "        print(\"write\")        \n",
    "        pseudobulk_path = Path(pseudobulk_file)\n",
    "        prop_path = Path(prop_file)\n",
    "        meta_path = Path(meta_file)\n",
    "        pickle.dump( prop_df, open( prop_path, \"wb\" ) )\n",
    "        pickle.dump( pseudobulks_df, open( pseudobulk_path, \"wb\" ) )\n",
    "        pickle.dump( metadata_df, open( meta_path, \"wb\" ) )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Bulks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in real bulk and format columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-fc0b58648cd9>:25: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs[\"tissue\"] = [x.split(\"_\")[0] for x in adata.obs[\"source name\"]]\n"
     ]
    }
   ],
   "source": [
    "data_path = f\"{os.getcwd()}/demo_data/bulk_data/\"\n",
    "\n",
    "\n",
    "in_file = f\"{data_path}/GSE132040_190214.csv\"\n",
    "meta_file = f\"{data_path}/GSE132040_MACA_Bulk_metadata.csv\"\n",
    "results_file = f\"{data_path}/liver_bulk_processed.h5ad\"\n",
    "\n",
    "with open(in_file) as your_data:\n",
    "    adata = ad.read_csv(your_data, delimiter=',')\n",
    "    adata = adata.transpose()\n",
    "    \n",
    "# add in all the metadata\n",
    "obs_df = pd.read_csv(meta_file)\n",
    "obs_df = obs_df.set_index(obs_df[\"Sample name\"] + \".gencode.vM19\")\n",
    "\n",
    "# remake anndata\n",
    "adata = ad.AnnData(adata.X, obs=obs_df, var=adata.var)\n",
    "\n",
    "# remove non-gene IDs\n",
    "gene_idx = np.where(np.logical_not(adata.var_names.str.startswith('__')))[0]\n",
    "adata = adata[:, gene_idx]\n",
    "\n",
    "# format the tissue \n",
    "adata.obs[\"tissue\"] = [x.split(\"_\")[0] for x in adata.obs[\"source name\"]]\n",
    "\n",
    "# subset to post-pubescent liver\n",
    "adata = adata[np.where(adata.obs[\"tissue\"] == \"Liver\")]\n",
    "adata = adata[np.where(adata.obs[\"characteristics: age\"] != \"1\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### format for BuDDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-53c7ec785cb6>:2: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  adata.obs['sample_id'] = adata.obs['source name']\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty column in cell metadata\n",
    "adata.obs['sample_id'] = adata.obs['source name']\n",
    "\n",
    "def get_stim_id(in_str):\n",
    "    out_str = \"STIM\"\n",
    "    if in_str == \"m\":\n",
    "        out_str = \"CTRL\"\n",
    "           \n",
    "    return(out_str)\n",
    "\n",
    "adata.obs['stim'] = [get_stim_id(str(x)) for x in adata.obs[\"characteristics: sex\"].tolist()]\n",
    "adata.var['gene_ids'] = adata.var.index.tolist()\n",
    "\n",
    "# write it out\n",
    "del adata.raw\n",
    "adata.write(results_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sc_bulk_ood",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
